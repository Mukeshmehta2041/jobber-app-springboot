version: "3.9"

services:
  # Database Services
  postgres:
    image: postgres:16-alpine
    container_name: jobber-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-jobber_prod}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
    networks:
      - jobber-backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres} -d ${POSTGRES_DB:-jobber_prod}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  mysql:
    image: mysql:8.0
    container_name: jobber-mysql
    restart: unless-stopped
    command: --default-authentication-plugin=mysql_native_password --innodb-buffer-pool-size=128M
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE:-jobber_auth}
      MYSQL_USER: ${MYSQL_USER:-jobber}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    ports:
      - "${MYSQL_PORT:-3306}:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./mysql-config:/etc/mysql/conf.d:ro
    networks:
      - jobber-backend
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "-p${MYSQL_ROOT_PASSWORD}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  mongodb:
    image: mongo:7.0
    container_name: jobber-mongodb
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE:-jobber}
    ports:
      - "${MONGO_PORT:-27017}:27017"
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
      - ./mongo-init:/docker-entrypoint-initdb.d:ro
    networks:
      - jobber-backend
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Cache Services
  redis:
    image: redis:7.2-alpine
    container_name: jobber-redis
    restart: unless-stopped
    command: redis-server --requirepass ${REDIS_PASSWORD} --maxmemory 256mb --maxmemory-policy allkeys-lru --appendonly yes
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
      - ./redis-config:/usr/local/etc/redis:ro
    networks:
      - jobber-backend
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  redis-commander:
    image: ghcr.io/joeferner/redis-commander:latest
    container_name: jobber-redis-commander
    restart: unless-stopped
    environment:
      REDIS_HOSTS: "production:jobber-redis:6379:0:${REDIS_PASSWORD}"
      HTTP_USER: ${REDIS_COMMANDER_USER:-admin}
      HTTP_PASSWORD: ${REDIS_COMMANDER_PASSWORD}
    ports:
      - "${REDIS_COMMANDER_PORT:-8082}:8081"
    networks:
      - jobber-backend
    depends_on:
      redis:
        condition: service_healthy
    profiles:
      - monitoring

  # Message Queue
  rabbitmq:
    image: rabbitmq:3.13-management-alpine
    container_name: jobber-rabbitmq
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-jobber}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: ${RABBITMQ_VHOST:-jobber}
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: 0.8
    ports:
      - "${RABBITMQ_PORT:-5672}:5672"
      - "${RABBITMQ_MANAGEMENT_PORT:-15672}:15672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./rabbitmq-config:/etc/rabbitmq:ro
    networks:
      - jobber-backend
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Search Engine
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: jobber-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
      - xpack.security.enabled=true
      - xpack.security.authc.api_key.enabled=true
      - xpack.monitoring.collection.enabled=true
      - xpack.security.enrollment.enabled=true
      - xpack.security.authc.token.enabled=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
      - network.host=0.0.0.0
      - http.host=0.0.0.0
      - transport.host=127.0.0.1
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "${ELASTICSEARCH_PORT:-9200}:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - ./elasticsearch-config:/usr/share/elasticsearch/config/custom:ro
    networks:
      - elastic
      - jobber-backend
    healthcheck:
      test: ["CMD-SHELL", "curl -s -u elastic:${ELASTIC_PASSWORD} http://localhost:9200/_cluster/health?pretty | grep -q '\"status\" : \"green\\|yellow\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    container_name: jobber-kibana
    restart: unless-stopped
    environment:
      ELASTICSEARCH_HOSTS: "http://jobber-elasticsearch:9200"
      ELASTICSEARCH_USERNAME: "kibana_system"
      ELASTICSEARCH_PASSWORD: ${KIBANA_PASSWORD}
      XPACK_FLEET_AGENTS_ELASTICSEARCH_HOSTS: '["http://jobber-elasticsearch:9200"]'
      SERVER_PUBLICBASEURL: "http://localhost:${KIBANA_PORT:-5601}"
    ports:
      - "${KIBANA_PORT:-5601}:5601"
    volumes:
      - kibana_data:/usr/share/kibana/data
      - ./kibana-config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro
    networks:
      - elastic
    depends_on:
      elasticsearch:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:5601/api/status | grep -q '\"overall\":{\"level\":\"available\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Application Services
  service-registry:
    build:
      context: ./services
      dockerfile: service-registry/Dockerfile
    image: ${DOCKER_REGISTRY:-mukeshkr24}/jobberapp-service-registry:${APP_VERSION:-latest}
    container_name: jobber-service-registry
    restart: unless-stopped
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-prod}
      SERVER_PORT: 8761
      MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE: health,info,metrics,prometheus
      MANAGEMENT_ENDPOINT_HEALTH_SHOW_DETAILS: when_authorized
    ports:
      - "${SERVICE_REGISTRY_PORT:-8761}:8761"
    networks:
      - jobber-backend
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8761/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  auth-service:
    build:
      context: ./services
      dockerfile: auth-service/Dockerfile
    image: ${DOCKER_REGISTRY:-mukeshkr24}/jobberapp-auth-service:${APP_VERSION:-latest}
    container_name: jobber-auth-service
    restart: unless-stopped
    environment:
      SPRING_PROFILES_ACTIVE: ${SPRING_PROFILES_ACTIVE:-prod}
      EUREKA_CLIENT_SERVICEURL_DEFAULTZONE: http://jobber-service-registry:8761/eureka
      SPRING_DATASOURCE_URL: jdbc:postgresql://jobber-postgres:5432/${POSTGRES_DB:-jobber_prod}
      SPRING_DATASOURCE_USERNAME: ${POSTGRES_USER:-postgres}
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      SPRING_REDIS_HOST: jobber-redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD}
      SPRING_RABBITMQ_HOST: jobber-rabbitmq
      SPRING_RABBITMQ_PORT: 5672
      SPRING_RABBITMQ_USERNAME: ${RABBITMQ_USER:-jobber}
      SPRING_RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE: health,info,metrics,prometheus
    ports:
      - "${AUTH_SERVICE_PORT:-8081}:8081"
    networks:
      - jobber-backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      service-registry:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8081/actuator/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 768M
        reservations:
          memory: 512M

  # Monitoring (Optional)
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: jobber-prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    networks:
      - jobber-backend
    profiles:
      - monitoring

  grafana:
    image: grafana/grafana:10.2.0
    container_name: jobber-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
      GF_USERS_ALLOW_SIGN_UP: "false"
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - jobber-backend
    profiles:
      - monitoring

networks:
  jobber-backend:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  elastic:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  mysql_data:
    driver: local
  mongodb_data:
    driver: local
  mongodb_config:
    driver: local
  redis_data:
    driver: local
  rabbitmq_data:
    driver: local
  elasticsearch_data:
    driver: local
  kibana_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local